{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "\n",
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "#from ultralytics import YOLO\n",
    "\n",
    "from utils.utils import list_file_r, copy_image_to_sub_dir\n",
    "from utils.data_augmentation import batch_augment_with_bbox, batch_augment_with_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "augmentor = A.Compose([\n",
    "    # Transform (random noises)\n",
    "    A.transforms.Spatter(p=0.2),\n",
    "    A.transforms.RandomFog(p=0.2),\n",
    "    A.transforms.RandomShadow(p=0.2),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    # Blur effect\n",
    "    A.MotionBlur(p=0.2),\n",
    "    A.Defocus(),\n",
    "    # Crop\n",
    "    #A.RandomCrop(width=450, height=450),\n",
    "    # Dropout\n",
    "    #   none\n",
    "    # Geometric\n",
    "    A.ShiftScaleRotate(rotate_limit=90, p=0.5),\n",
    "    #A.HorizontalFlip(p=0.1),\n",
    "    #A.Rotate(),\n",
    "    A.FDA(reference_images=[cv2.imread('datasets/CF_simulation/real_image/test/hdt5_0010.tif')],read_fn=lambda x:x,p=1)], \n",
    "    bbox_params=A.BboxParams(format='yolo', min_visibility=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('datasets/CF_simulation/images/01_line_Radius4_2_Density1500_1000_Width50_Reflection_0.tif')\n",
    "bbox = np.loadtxt('datasets/CF_simulation/bbox/01_line_Radius4_2_Density1500_1000_Width50_Reflection_0.txt', delimiter=' ')\n",
    "bbox = np.concatenate((bbox, bbox[:,0:1]), axis=-1)[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.random.randint(0, 256, [100, 100, 3], dtype=np.uint8)\n",
    "target_temp = np.random.randint(0, 256, [100, 100, 3], dtype=np.uint8)\n",
    "aug = A.Compose([A.FDA([target_temp], p=1, read_fn=lambda x: x)])\n",
    "result = aug(image=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented = augmentor(image=img,bboxes=bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(augmented['image']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.79821737, 0.61650781, 0.40356525, 0.76698438, 0.        ],\n",
       "       [0.72620155, 0.5829415 , 0.54155936, 0.834117  , 0.        ],\n",
       "       [0.58518868, 0.54937519, 0.54155936, 0.90124962, 0.        ],\n",
       "       [0.4441758 , 0.51580888, 0.54155936, 0.96838223, 0.        ],\n",
       "       [0.30316292, 0.47466304, 0.54155936, 0.94932607, 0.        ],\n",
       "       [0.21646486, 0.44109673, 0.43292973, 0.88219346, 0.        ],\n",
       "       [0.14595842, 0.40753042, 0.29191685, 0.81506084, 0.        ]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(augmented['bboxes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.79821737, 0.61650781, 0.40356525, 0.76698438],\n",
       "       [0.        , 0.72620155, 0.5829415 , 0.54155936, 0.834117  ],\n",
       "       [0.        , 0.58518868, 0.54937519, 0.54155936, 0.90124962],\n",
       "       [0.        , 0.4441758 , 0.51580888, 0.54155936, 0.96838223],\n",
       "       [0.        , 0.30316292, 0.47466304, 0.54155936, 0.94932607],\n",
       "       [0.        , 0.21646486, 0.44109673, 0.43292973, 0.88219346],\n",
       "       [0.        , 0.14595842, 0.40753042, 0.29191685, 0.81506084]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = np.array(augmented['bboxes'])\n",
    "res = np.concatenate((res[:,-1:], res), axis=-1)[:,:-1]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = pd.DataFrame(res)\n",
    "#res[:,0] = res[:,0].astype(int)\n",
    "np.savetxt('test.txt',res, fmt=' '.join(['%i']+['%1.4f']*4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor = A.Compose([\n",
    "    # Transform (random noises)\n",
    "    A.transforms.Spatter(p=0.2),\n",
    "    A.transforms.RandomFog(p=0.2, fog_coef_lower=0.1, fog_coef_upper=0.4),\n",
    "    A.transforms.RandomShadow(p=0.2),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    # Blur effect\n",
    "    A.MotionBlur(p=0.2),\n",
    "    A.Defocus(p=0.2),\n",
    "    # Crop\n",
    "    A.BBoxSafeRandomCrop(p=0.5),\n",
    "    # Dropout\n",
    "    #   none\n",
    "    # Geometric\n",
    "    A.ShiftScaleRotate(rotate_limit=45, p=0.75)\n",
    "    #A.HorizontalFlip(p=0.1),\n",
    "    #A.Rotate(),\n",
    "], bbox_params=A.BboxParams(format='yolo', min_visibility=0.2))\n",
    "\n",
    "#batch_augment_with_bbox(images_path='datasets/CF_simulation/images/', bbox_path='datasets/CF_simulation/bbox', augmentor=augmentor, random_choice=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [\n",
    "    # Blur effect\n",
    "    A.MotionBlur(p=0.2, blur_limit=5),\n",
    "    A.Defocus(p=0.2, alias_blur=0.3),\n",
    "    # Crop\n",
    "    #A.BBoxSafeRandomCrop(p=0.5),\n",
    "    A.RandomCrop(640, 640, p=0.5),\n",
    "    # Dropout\n",
    "    #   none\n",
    "    # Geometric\n",
    "    A.ShiftScaleRotate(rotate_limit=45, p=0.75),\n",
    "    #A.HorizontalFlip(p=0.1),\n",
    "    #A.Rotate(),\n",
    "    # Transform (random noises),\n",
    "    A.transforms.Spatter(p=0.2),\n",
    "    A.transforms.RandomFog(p=0.2, fog_coef_lower=0.02, fog_coef_upper=0.1),\n",
    "    A.transforms.RandomShadow(p=0.2),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "]\n",
    "\n",
    "batch_augment_with_mask(images_path='datasets/CF_simulation/images/', mask_path='datasets/CF_simulation/mask/', transforms=transforms, FDA_targets='real_image/FDA_targets', random_choice=1.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
