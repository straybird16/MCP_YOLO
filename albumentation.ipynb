{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "#from ultralytics import YOLO\n",
    "\n",
    "from utils.utils import list_file_r, copy_image_to_sub_dir\n",
    "from utils.data_augmentation import batch_augment_with_bbox, batch_augment_with_mask, batch_invers_FDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270 333\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('datasets/CF_simulation/images/01_line_Radius4_2_Density1500_1000_Width50_Reflection_0.tif')\n",
    "bbox = np.loadtxt('datasets/CF_simulation/bbox/01_line_Radius4_2_Density1500_1000_Width50_Reflection_0.txt', delimiter=' ')\n",
    "bbox = np.concatenate((bbox, bbox[:,0:1]), axis=-1)[:,1:]\n",
    "img_h, img_w, _ = img.shape\n",
    "#print(img.shape)\n",
    "r = np.random.default_rng()\n",
    "resize_h, resize_w = r.random()*0.5, r.random()*0.9\n",
    "resize_h, resize_w = int(resize_h*img_h), int(resize_w*img_w)\n",
    "print(resize_h, resize_w)\n",
    "augmentor = A.Compose([\n",
    "    # Transform (random noises)\n",
    "    A.Resize(resize_h, resize_w, p=1.0),\n",
    "    A.transforms.Spatter(p=0.2),\n",
    "    A.transforms.RandomFog(p=0.2),\n",
    "    A.transforms.RandomShadow(p=0.2),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    # Blur effect\n",
    "    A.MotionBlur(p=0.2),\n",
    "    A.Defocus(),\n",
    "    # Crop\n",
    "    #A.RandomCrop(width=450, height=450),\n",
    "    # Dropout\n",
    "    #   none\n",
    "    # Geometric\n",
    "    A.ShiftScaleRotate(rotate_limit=90, p=0.5),\n",
    "    #A.HorizontalFlip(p=0.1),\n",
    "    #A.Rotate(),\n",
    "    #A.FDA(reference_images=[cv2.imread('datasets/CF_simulation/real_image/test/hdt5_0010.tif')],read_fn=lambda x:x,p=1)\n",
    "    ]\n",
    "    ,bbox_params=A.BboxParams(format='yolo', min_visibility=0.2))\n",
    "\n",
    "augmented = augmentor(image=img,bboxes=bbox)\n",
    "Image.fromarray(augmented['image']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('datasets/CF_simulation/images/01_line_Radius4_2_Density1500_1000_Width50_Reflection_0.tif')\n",
    "bbox = np.loadtxt('datasets/CF_simulation/bbox/01_line_Radius4_2_Density1500_1000_Width50_Reflection_0.txt', delimiter=' ')\n",
    "bbox = np.concatenate((bbox, bbox[:,0:1]), axis=-1)[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.random.randint(0, 256, [100, 100, 3], dtype=np.uint8)\n",
    "target_temp = np.random.randint(0, 256, [100, 100, 3], dtype=np.uint8)\n",
    "aug = A.Compose([A.FDA([target_temp], p=1, read_fn=lambda x: x)])\n",
    "result = aug(image=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented = augmentor(image=img,bboxes=bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor = A.Compose([\n",
    "    # Transform (random noises)\n",
    "    A.transforms.Spatter(p=0.2),\n",
    "    A.transforms.RandomFog(p=0.2, fog_coef_lower=0.1, fog_coef_upper=0.4),\n",
    "    A.transforms.RandomShadow(p=0.2),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    # Blur effect\n",
    "    A.MotionBlur(p=0.2),\n",
    "    A.Defocus(p=0.2),\n",
    "    # Crop\n",
    "    A.BBoxSafeRandomCrop(p=0.5),\n",
    "    # Dropout\n",
    "    #   none\n",
    "    # Geometric\n",
    "    A.ShiftScaleRotate(rotate_limit=45, p=0.75)\n",
    "    #A.HorizontalFlip(p=0.1),\n",
    "    #A.Rotate(),\n",
    "], bbox_params=A.BboxParams(format='yolo', min_visibility=0.2))\n",
    "\n",
    "#batch_augment_with_bbox(images_path='datasets/CF_simulation/images/', bbox_path='datasets/CF_simulation/bbox', augmentor=augmentor, random_choice=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'D:/xie/Vision/mcp_yolo/datasets/CF_simulation/mask'\n",
    "for fn in os.listdir(folder):\n",
    "    if fn[3:7] == 'line':\n",
    "        os.rename(os.path.join(folder, fn), os.path.join(folder, 'line', fn)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [\n",
    "    # Blur effect\n",
    "    A.MotionBlur(p=0.2, blur_limit=5),\n",
    "    #A.Defocus(p=0.2, alias_blur=0.3),\n",
    "    # Dropout\n",
    "    #   none\n",
    "    # Geometric\n",
    "    A.ShiftScaleRotate(rotate_limit=180, p=0.75),\n",
    "    # Transform (random noises),\n",
    "    A.transforms.Spatter(p=0.2),\n",
    "    A.transforms.RandomFog(p=0.2, fog_coef_lower=0.02, fog_coef_upper=0.1),\n",
    "    A.transforms.RandomShadow(p=0.2),\n",
    "    # Photometric\n",
    "    A.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, p=0.2),\n",
    "    #A.RandomBrightnessContrast(p=0.2),\n",
    "    # Crop\n",
    "    #A.BBoxSafeRandomCrop(p=0.6),\n",
    "    A.RandomCrop(720, 720, p=0.2),\n",
    "    A.RandomCrop(640, 640, p=0.2),\n",
    "    A.RandomCrop(480, 480, p=0.2),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [\n",
    "    # Blur effect\n",
    "    #A.MotionBlur(p=1, blur_limit=9),\n",
    "    #A.Defocus(p=1, alias_blur=0.3),\n",
    "    # Dropout\n",
    "    #   none\n",
    "    # Geometric\n",
    "    A.ShiftScaleRotate(rotate_limit=180, p=0.75),\n",
    "    # Transform (random noises),\n",
    "    #A.transforms.Spatter(p=0.2),\n",
    "    #A.transforms.RandomFog(p=0.2, fog_coef_lower=0.02, fog_coef_upper=0.1),\n",
    "    A.transforms.RandomShadow(p=1),\n",
    "    # Photometric\n",
    "    #A.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
    "    #A.RandomBrightnessContrast(p=0.2),\n",
    "    # Crop\n",
    "    #A.BBoxSafeRandomCrop(p=0.5),\n",
    "    A.RandomCrop(720, 720, p=0.1),\n",
    "    A.RandomCrop(640, 640, p=0.1),\n",
    "    A.RandomCrop(480, 480, p=0.1),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_augment_with_mask(images_path='datasets/CF_simulation/images/real', mask_path='datasets/CF_simulation/mask/real', target_folder='real',  random_choice=2000, transforms=transforms, FDA_targets=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_augment_with_mask(images_path='datasets/CF_simulation/images/line', mask_path='datasets/CF_simulation/mask/line', transforms=transforms, FDA_targets=None, random_choice=12000)\n",
    "batch_augment_with_mask(images_path='datasets/CF_simulation/images/supp1', mask_path='datasets/CF_simulation/mask/supp1', transforms=transforms, FDA_targets=None, random_choice=3000)\n",
    "batch_augment_with_mask(images_path='datasets/CF_simulation/images/supp2', mask_path='datasets/CF_simulation/mask/supp2', transforms=transforms, FDA_targets=None, random_choice=3000)\n",
    "batch_augment_with_mask(images_path='datasets/CF_simulation/images/supp3', mask_path='datasets/CF_simulation/mask/supp3', transforms=transforms, FDA_targets=None, random_choice=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imp in list_file_r('datasets/CF_simulation/mask/background'):\n",
    "    img=np.array(Image.open(imp))\n",
    "    img = Image.fromarray(img>0)\n",
    "    img.save(imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply inverseFDA\n",
    "FDA_targets='datasets/CF_simulation/RDA_targets'\n",
    "image_folder = 'datasets/CF_simulation/images/line/RDA_large/11'\n",
    "batch_invers_FDA(src=image_folder, FDA_targets=FDA_targets, beta=0.4, p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320 320 33 33\n"
     ]
    }
   ],
   "source": [
    "from utils.fft import inverseFDA\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "\n",
    "src_path = 'datasets/CF_simulation/images/supp2/augmented/01_line_Radius3_1_Density4000_500_Width20_Reflection_02.tif'\n",
    "tgt_path = 'datasets/CF_simulation/real_image/test_gs/hdt_0146.tif'\n",
    "tgt_path = 'datasets/CF_simulation/real_image/test_gs/image490.bmp'\n",
    "\n",
    "src, tgt = Image.open(src_path), Image.open(tgt_path)\n",
    "tgt = tgt.resize(src.size)\n",
    "src, tgt = np.array(src), np.array(tgt)\n",
    "img = Image.fromarray(inverseFDA(src, tgt, beta=0.8))\n",
    "img.save('0.8.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
