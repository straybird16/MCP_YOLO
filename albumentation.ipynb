{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "\n",
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "#from ultralytics import YOLO\n",
    "\n",
    "from utils.utils import list_file_r, copy_image_to_sub_dir\n",
    "from utils.data_augmentation import batch_augment_with_bbox, batch_augment_with_mask, batch_invers_FDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1000, 3)\n",
      "3.4560039043426514\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import time\n",
    "img = cv2.imread('datasets/CF_simulation/images/01_line_Radius4_2_Density1500_1000_Width50_Reflection_0.tif')\n",
    "assert img is not None, \"file could not be read, check with os.path.exists()\"\n",
    "#img = cv.medianBlur(img,5)\n",
    "print(img.shape)\n",
    "cimg = cv.cvtColor(img, cv.COLOR_RGB2GRAY)\n",
    "img = img.mean(axis=-1)\n",
    "start = time.time()\n",
    "img = np.array(img, dtype=np.uint8)\n",
    "\n",
    "# thresholding\n",
    "#img = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY,5,1)\n",
    "img = cv.Canny(img, 100, 200)\n",
    "Image.fromarray(img).show()\n",
    "#\n",
    "#circles = cv.HoughCircles(img,cv.HOUGH_GRADIENT,1,5,param1=50,param2=30,minRadius=1,maxRadius=20)\n",
    "circles = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT, 1, 5, np.array([]), 40, 23, 1,20)\n",
    "circles = np.uint16(np.around(circles))\n",
    "print(time.time()-start)\n",
    "for i in circles[0,:]:\n",
    "    # draw the outer circle\n",
    "    cv.circle(cimg,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "    # draw the center of the circle\n",
    "    cv.circle(cimg,(i[0],i[1]),2,(0,0,255),3)\n",
    "\n",
    "cv.imshow('detected circles',cimg)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270 333\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('datasets/CF_simulation/images/01_line_Radius4_2_Density1500_1000_Width50_Reflection_0.tif')\n",
    "bbox = np.loadtxt('datasets/CF_simulation/bbox/01_line_Radius4_2_Density1500_1000_Width50_Reflection_0.txt', delimiter=' ')\n",
    "bbox = np.concatenate((bbox, bbox[:,0:1]), axis=-1)[:,1:]\n",
    "img_h, img_w, _ = img.shape\n",
    "#print(img.shape)\n",
    "r = np.random.default_rng()\n",
    "resize_h, resize_w = r.random()*0.5, r.random()*0.9\n",
    "resize_h, resize_w = int(resize_h*img_h), int(resize_w*img_w)\n",
    "print(resize_h, resize_w)\n",
    "augmentor = A.Compose([\n",
    "    # Transform (random noises)\n",
    "    A.Resize(resize_h, resize_w, p=1.0),\n",
    "    A.transforms.Spatter(p=0.2),\n",
    "    A.transforms.RandomFog(p=0.2),\n",
    "    A.transforms.RandomShadow(p=0.2),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    # Blur effect\n",
    "    A.MotionBlur(p=0.2),\n",
    "    A.Defocus(),\n",
    "    # Crop\n",
    "    #A.RandomCrop(width=450, height=450),\n",
    "    # Dropout\n",
    "    #   none\n",
    "    # Geometric\n",
    "    A.ShiftScaleRotate(rotate_limit=90, p=0.5),\n",
    "    #A.HorizontalFlip(p=0.1),\n",
    "    #A.Rotate(),\n",
    "    #A.FDA(reference_images=[cv2.imread('datasets/CF_simulation/real_image/test/hdt5_0010.tif')],read_fn=lambda x:x,p=1)\n",
    "    ]\n",
    "    ,bbox_params=A.BboxParams(format='yolo', min_visibility=0.2))\n",
    "\n",
    "augmented = augmentor(image=img,bboxes=bbox)\n",
    "Image.fromarray(augmented['image']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('datasets/CF_simulation/images/01_line_Radius4_2_Density1500_1000_Width50_Reflection_0.tif')\n",
    "bbox = np.loadtxt('datasets/CF_simulation/bbox/01_line_Radius4_2_Density1500_1000_Width50_Reflection_0.txt', delimiter=' ')\n",
    "bbox = np.concatenate((bbox, bbox[:,0:1]), axis=-1)[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.random.randint(0, 256, [100, 100, 3], dtype=np.uint8)\n",
    "target_temp = np.random.randint(0, 256, [100, 100, 3], dtype=np.uint8)\n",
    "aug = A.Compose([A.FDA([target_temp], p=1, read_fn=lambda x: x)])\n",
    "result = aug(image=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented = augmentor(image=img,bboxes=bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(augmented['image']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5 , 0.95, 1.  , 0.1 , 0.  ],\n",
       "       [0.5 , 0.8 , 1.  , 0.1 , 0.  ],\n",
       "       [0.5 , 0.65, 1.  , 0.1 , 0.  ],\n",
       "       [0.5 , 0.5 , 1.  , 0.1 , 0.  ],\n",
       "       [0.5 , 0.35, 1.  , 0.1 , 0.  ],\n",
       "       [0.5 , 0.2 , 1.  , 0.1 , 0.  ],\n",
       "       [0.5 , 0.05, 1.  , 0.1 , 0.  ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(augmented['bboxes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.79821737, 0.61650781, 0.40356525, 0.76698438],\n",
       "       [0.        , 0.72620155, 0.5829415 , 0.54155936, 0.834117  ],\n",
       "       [0.        , 0.58518868, 0.54937519, 0.54155936, 0.90124962],\n",
       "       [0.        , 0.4441758 , 0.51580888, 0.54155936, 0.96838223],\n",
       "       [0.        , 0.30316292, 0.47466304, 0.54155936, 0.94932607],\n",
       "       [0.        , 0.21646486, 0.44109673, 0.43292973, 0.88219346],\n",
       "       [0.        , 0.14595842, 0.40753042, 0.29191685, 0.81506084]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = np.array(augmented['bboxes'])\n",
    "res = np.concatenate((res[:,-1:], res), axis=-1)[:,:-1]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = pd.DataFrame(res)\n",
    "#res[:,0] = res[:,0].astype(int)\n",
    "np.savetxt('test.txt',res, fmt=' '.join(['%i']+['%1.4f']*4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor = A.Compose([\n",
    "    # Transform (random noises)\n",
    "    A.transforms.Spatter(p=0.2),\n",
    "    A.transforms.RandomFog(p=0.2, fog_coef_lower=0.1, fog_coef_upper=0.4),\n",
    "    A.transforms.RandomShadow(p=0.2),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    # Blur effect\n",
    "    A.MotionBlur(p=0.2),\n",
    "    A.Defocus(p=0.2),\n",
    "    # Crop\n",
    "    A.BBoxSafeRandomCrop(p=0.5),\n",
    "    # Dropout\n",
    "    #   none\n",
    "    # Geometric\n",
    "    A.ShiftScaleRotate(rotate_limit=45, p=0.75)\n",
    "    #A.HorizontalFlip(p=0.1),\n",
    "    #A.Rotate(),\n",
    "], bbox_params=A.BboxParams(format='yolo', min_visibility=0.2))\n",
    "\n",
    "#batch_augment_with_bbox(images_path='datasets/CF_simulation/images/', bbox_path='datasets/CF_simulation/bbox', augmentor=augmentor, random_choice=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [\n",
    "    # Blur effect\n",
    "    A.MotionBlur(p=0.2, blur_limit=5),\n",
    "    A.Defocus(p=0.2, alias_blur=0.3),\n",
    "    # Dropout\n",
    "    #   none\n",
    "    # Geometric\n",
    "    A.ShiftScaleRotate(rotate_limit=180, p=0.75),\n",
    "    #A.HorizontalFlip(p=0.1),\n",
    "    #A.Rotate(),\n",
    "    # Transform (random noises),\n",
    "    A.transforms.Spatter(p=0.2),\n",
    "    A.transforms.RandomFog(p=0.2, fog_coef_lower=0.02, fog_coef_upper=0.1),\n",
    "    A.transforms.RandomShadow(p=0.2),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    # Crop\n",
    "    #A.BBoxSafeRandomCrop(p=0.5),\n",
    "    A.RandomCrop(640, 640, p=0.1),\n",
    "]\n",
    "\n",
    "batch_augment_with_mask(images_path='datasets/CF_simulation/images/background', mask_path='datasets/CF_simulation/mask/background', transforms=transforms, FDA_targets=None, random_choice=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open('D:\\\\xie\\\\Vision\\\\mcp_yolo\\\\datasets\\\\CF_simulation\\\\mask\\\\augmented\\\\01_line_Radius4_2_Density1500_1000_Width100_Reflection_0.tif').show()\n",
    "Image.open('D:\\\\xie\\\\Vision\\\\mcp_yolo\\\\datasets\\\\CF_simulation\\\\images\\\\augmented\\\\01_line_Radius4_2_Density1500_1000_Width100_Reflection_0.tif').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imp in list_file_r('datasets/CF_simulation/mask/background'):\n",
    "    img=np.array(Image.open(imp))\n",
    "    img = Image.fromarray(img>0)\n",
    "    img.save(imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply inverseFDA\n",
    "batch_invers_FDA(src='datasets/CF_simulation/images/augmented/train', FDA_targets='datasets/CF_simulation/images/augmented/val', beta=0.4, p=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320 320 33 33\n"
     ]
    }
   ],
   "source": [
    "from utils.fft import inverseFDA\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "\n",
    "src_path = 'datasets/CF_simulation/images/supp2/augmented/01_line_Radius3_1_Density4000_500_Width20_Reflection_02.tif'\n",
    "tgt_path = 'datasets/CF_simulation/real_image/test_gs/hdt_0146.tif'\n",
    "tgt_path = 'datasets/CF_simulation/real_image/test_gs/image490.bmp'\n",
    "\n",
    "src, tgt = Image.open(src_path), Image.open(tgt_path)\n",
    "tgt = tgt.resize(src.size)\n",
    "src, tgt = np.array(src), np.array(tgt)\n",
    "img = Image.fromarray(inverseFDA(src, tgt, beta=0.8))\n",
    "img.save('0.8.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
